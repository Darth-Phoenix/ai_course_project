{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ori_data = pd.read_csv('./data/v2-1.csv', index_col=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [\n",
    "    'Distance(mi)', 'Temperature(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)',\n",
    "    'Wind_Speed(mph)', 'elapsed_time'\n",
    "]\n",
    "\n",
    "info_cols = ['Severity', 'Start_Lat', 'Start_Lng', 'Weather_Timestamp', 'Hour', 'Day', 'Minute']\n",
    "categorical_features = [f for f in list(ori_data.columns) if (f not in numerical_features and f not in info_cols)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "for column in categorical_features:\n",
    "    ori_data[column] = label_encoder.fit_transform(ori_data[column])\n",
    "    ori_data[column] = ori_data[column].astype(np.int32)\n",
    "\n",
    "# process continous value to float32\n",
    "for column in numerical_features:\n",
    "    ori_data[column] = ori_data[column].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_data.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_data.to_csv('./data/v3.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, StackingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from collections import Counter\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_data = pd.read_csv('./data/v3.csv', index_col=False)\n",
    "numerical_features = [\n",
    "    'Distance(mi)', 'Temperature(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)',\n",
    "    'Wind_Speed(mph)', 'elapsed_time'\n",
    "]\n",
    "\n",
    "info_cols = ['Severity', 'Start_Lat', 'Start_Lng', 'Weather_Timestamp', 'Hour', 'Day', 'Minute']\n",
    "categorical_features = [f for f in list(ori_data.columns) if (f not in numerical_features and f not in info_cols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ori_data.drop(info_cols, axis=1)\n",
    "y = ori_data['Severity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_scoring(y_true, y_pred, verbose=False):\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    total_f1 = 0\n",
    "    beta_weights = {\n",
    "        '1': 0.5,\n",
    "        '2': 1,\n",
    "        '3': 1,\n",
    "        '4': 2,\n",
    "    }\n",
    "    for cl in range(1, 5):\n",
    "        pr = report[str(cl)]['precision']\n",
    "        rc = report[str(cl)]['recall']\n",
    "        beta = beta_weights[str(cl)]\n",
    "        beta_f1 = ((1+beta**2)*pr*rc)/(pr*(beta**2) + rc)\n",
    "        if verbose: \n",
    "            print(f'beta f1 for level [{cl}]: {beta_f1}, pr: {pr}, rc: {rc}')\n",
    "        total_f1 += beta_f1\n",
    "\n",
    "    avg_f1 = total_f1/4\n",
    "    if verbose:\n",
    "        print(f\"macro avg for f1: {avg_f1}\")\n",
    "    return avg_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def cross_valid(X, y, estimator, cv=5, verbose=False):\n",
    "    round = 1\n",
    "    total_f1 = 0\n",
    "    x_train_valid, x_test, y_train_valid, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "    x_train_valid.reset_index()\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    print('Validation data')\n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(x_train_valid)):\n",
    "        x_train, x_valid = x_train_valid.iloc[train_index], x_train_valid.iloc[valid_index]\n",
    "        y_train, y_valid = y_train_valid.iloc[train_index], y_train_valid.iloc[valid_index]\n",
    "        \n",
    "        x_train_balan, y_train_balan = rus.fit_resample(x_train, y_train)\n",
    "        # if verbose:\n",
    "        #     print('After under sampling:')\n",
    "        #     print(f'Length of training data: {len(x_train_balan)}, and its distribution among each severity {Counter(y_train_balan)}')\n",
    "\n",
    "        estimator.fit(x_train_balan, y_train_balan)\n",
    "        y_valid_pred = estimator.predict(x_valid)\n",
    "        beta_f1 = custom_scoring(y_valid, y_valid_pred, verbose=False)\n",
    "        print(f'Round {round} beta_f1: {beta_f1}')\n",
    "        total_f1 += beta_f1\n",
    "        round += 1\n",
    "        \n",
    "    avg_betaf1 = total_f1 / cv\n",
    "    print(f'average beta f1-score: {avg_betaf1}')\n",
    "\n",
    "    print('Testing data')\n",
    "    y_test_pred = estimator.predict(x_test)\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    beta_f1 = custom_scoring(y_test, y_test_pred, verbose=True)\n",
    "    print(f'beta f1-score: {beta_f1}')\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalance testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data\n",
      "Round 1 beta_f1: 0.4120755017415445\n",
      "Round 2 beta_f1: 0.4132266914387351\n",
      "Round 3 beta_f1: 0.41248355656196034\n",
      "Round 4 beta_f1: 0.41139465321208984\n",
      "Round 5 beta_f1: 0.41079151409006953\n",
      "average beta f1-score: 0.4119943834088799\n",
      "Testing data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.08      0.81      0.14     13140\n",
      "           2       0.93      0.57      0.70   1191687\n",
      "           3       0.43      0.64      0.52    252647\n",
      "           4       0.11      0.71      0.18     38727\n",
      "\n",
      "    accuracy                           0.58   1496201\n",
      "   macro avg       0.39      0.68      0.39   1496201\n",
      "weighted avg       0.81      0.58      0.65   1496201\n",
      "\n",
      "beta f1 for level [1]: 0.09687839305103149, pr: 0.07939050161272383, rc: 0.8148401826484019\n",
      "beta f1 for level [2]: 0.7031377639078272, pr: 0.9262645882372307, rc: 0.5666404013805638\n",
      "beta f1 for level [3]: 0.5165989732725422, pr: 0.43269490297943075, rc: 0.6408704635321218\n",
      "beta f1 for level [4]: 0.33123261337471827, pr: 0.10600290556900727, rc: 0.7065354920339815\n",
      "macro avg for f1: 0.4119619359015298\n",
      "beta f1-score: 0.4119619359015298\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "cross_valid(X, y, dt, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.89      0.87     13140\n",
      "           2       0.69      0.53      0.60     13140\n",
      "           3       0.72      0.74      0.73     13140\n",
      "           4       0.71      0.82      0.76     13140\n",
      "\n",
      "    accuracy                           0.75     52560\n",
      "   macro avg       0.74      0.75      0.74     52560\n",
      "weighted avg       0.74      0.75      0.74     52560\n",
      "\n",
      "beta f1 for level [1]: 0.8610980068404293, pr: 0.8543845534995977, rc: 0.8890410958904109\n",
      "beta f1 for level [2]: 0.6013835775362008, pr: 0.690614822856015, rc: 0.532572298325723\n",
      "beta f1 for level [3]: 0.7303509362036102, pr: 0.7175589336858339, rc: 0.743607305936073\n",
      "beta f1 for level [4]: 0.7945699218576894, pr: 0.7107088590870053, rc: 0.8187214611872146\n",
      "macro avg for f1: 0.7468506106094824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7468506106094824"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=15), n_estimators=100)\n",
    "abc.fit(x_res, y_res)\n",
    "y_pred = abc.predict(x_res_test)\n",
    "\n",
    "print(classification_report(y_res_test, y_pred))\n",
    "custom_scoring(y_res_test, y_pred, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
